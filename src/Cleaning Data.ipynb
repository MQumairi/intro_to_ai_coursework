{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "\n",
    "## Research Question: \"Predict whether a stop and search will conclude in police action\".\n",
    "\n",
    "#### In this notebook we attempt to answer the research question using the data set (https://www.kaggle.com/sohier/london-police-records?select=london-stop-and-search.csv). First we clean the data from null values."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "We import the libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "source": [
    "We import the dataset. It is \"london-stop-and-search.csv\", retrieved from Kaggle (https://www.kaggle.com/sohier/london-police-records?select=london-stop-and-search.csv), then cleaned by having some columns removed (\"part of police operation\", \"police operation\", and \"self-defined ethnicity\")."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data.csv\")\n",
    "\n",
    "# Programatically remove the columns: \n",
    "#   - \"Outcome linked to object of search\"\n",
    "#   - \"Removal of more than just outer clothing\". \n",
    "\n",
    "# Reason: too many nulls. For the former, not something that is relevant before the police action- so irrelevant to research question.\n",
    "# TODO: discuss wether the csv file needs to be modified to reflect this.\n",
    "del data[\"Outcome linked to object of search\"]\n",
    "del data[\"Removal of more than just outer clothing\"]\n",
    "\n",
    "# We print information about our data object (the csv file), which displays the number non-empty (\"non-Null\") values for each column, as well as the types of their values.\n",
    "# PS: Most columns have a \"Dtype\" of \"object\"... probably means string\n",
    "print(data.info())\n"
   ]
  },
  {
   "source": [
    "Columns for this dataset are either numerical (e.g. Latitude) or categorical (e.g. Gender, describing a category of things). \n",
    "\n",
    "For categorical columns, we can't calculate medians (how to calculate medians for string values!?), but we can do so for our numerical columns. Specifically, the two nmerical columns are Latitude and Longitude. \n",
    "\n",
    "Furthermore, we can convert all values under \"Date\" to type DateTime using pd.to_datetime.\n",
    "\n",
    "Finally, we drop all rows with empty values using .dropna()"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert latitude and longitude nulls to median\n",
    "lat_median = data[\"Latitude\"].median()\n",
    "lon_median = data[\"Longitude\"].median()\n",
    "\n",
    "data[\"Latitude\"] = data[\"Latitude\"].fillna(lat_median)\n",
    "data[\"Longitude\"] = data[\"Longitude\"].fillna(lon_median)\n",
    "\n",
    "#Change the \"Date\" column to type DateTime\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "\n",
    "# Some of the values for \"Age range\" have an inexplicable value of \"Oct-17... those will be removed as well\"\n",
    "# Reference for dictionary idea to replace values: https://stackoverflow.com/questions/17114904/python-pandas-replacing-strings-in-dataframe-with-numbers\n",
    "oct17_to_None = {\"Oct-17\": None}\n",
    "data = data.applymap(lambda s: oct17_to_None.get(s) if s in oct17_to_None else s)\n",
    "\n",
    "#For other columsn we'll need to drop the null values \n",
    "data = data.dropna()\n",
    "\n",
    "#Let's print data.info again to see the changes\n",
    "print(data.info())\n",
    "\n",
    "#Notice: for each column, the number of non-null rows is equal to the number of rows in the table (165,651). Hence, no column has empty values under it.\n",
    "#Noitce: the type of Date is now datetime64[ns, UTC]"
   ]
  },
  {
   "source": [
    "## Encoding data \n",
    "\n",
    "Most sklearn functions don't expect string values. Unfortunately our dataset is filled with those. We need to therefore encode them into numerical types. Below, we build on the method outlined in ex5Part2 (Lab 5 of Introduction to AI module), using LabelEncoder from sklearn, to automatically encode our strings into numerals.\n",
    "\n",
    "Our process will proceed as follows:\n",
    "\n",
    "1. We build a dictionary to store an instance of LabelEncoder for each 'categorical column' (the seven labels assigned as a list to the variable \"categorical_cols\" below). We exclude any numerical columns (i.e. Date, Latitude, and Longitude) because those don't need to be encoded.\n",
    "2. We iterate over the columns in our dataset. For each categorical column, we instantiate a corresponding encoder of type LabelEncoder(). The goal is to be able to access the specific encoder used to encode a particular column, thus allowing us to see the original string values (using encoder.classes_), and map them to the encoded number. This benefit will be made clearer in the 'Encoder Mapper' below.\n",
    "3. We copy our dataset \"data\", into a variable \"data_encoded\". We will replace the categorical values of \"data_encoded\" with the encoded numerals, and leave the cleaned dataset of strings (\"data\") untouched. May prove to be useful later.\n",
    "4. We iterate over the columns in \"data_encoded\", and transform all strings to an appropriate numeral, using the corresponding encoder in the \"encoders\" dictionary, as shown in lab 5."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a dictionary of Encoders\n",
    "encoders = {}\n",
    "categorical_cols = [\"Type\", \"Gender\", \"Age range\", \"Officer-defined ethnicity\", \"Legislation\", \"Object of search\", \"Outcome\"]\n",
    "\n",
    "for label in categorical_cols:\n",
    "    encoders[f\"{label} Encoder\"] = LabelEncoder()\n",
    "    encoders[f\"{label} Encoder\"].fit(data[label])\n",
    "\n",
    "print(encoders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoder Mapper\n",
    "# The purpose is to access the encoders in the \"encoders\" dictionary, and use them to map the string value we're going to encode, to the corresponding numeral for that column.\n",
    "encoders[\"Outcome Encoder\"].classes_\n",
    "\n",
    "for label in categorical_cols:\n",
    "    print(f\"Encoder dictionary for {label}:\")\n",
    "    categories = encoders[f\"{label} Encoder\"].classes_\n",
    "    for i in range(len(categories)):\n",
    "        numeral = encoders[f\"{label} Encoder\"].transform([categories[i]])\n",
    "        print(f\"'{categories[i]}' encoded to '{numeral[0]}'\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We copy data, so data_encoded and data are two different objects (such that changing one won't impact the other)\n",
    "data_encoded = data.copy() \n",
    "\n",
    "#We perform the encoding to data_encoded\n",
    "for label in categorical_cols:\n",
    "    data_encoded[label] = encoders[f\"{label} Encoder\"].fit(data[label]).transform(data[label])\n",
    "\n",
    "#Print the data_encoded... notice all values have been numerified!\n",
    "data_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#But \"data\" remains as it was...\n",
    "data.head()\n",
    "\n",
    "#You can use the Encoder Mapper to map between the numrical values in data_encoded and the original string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}